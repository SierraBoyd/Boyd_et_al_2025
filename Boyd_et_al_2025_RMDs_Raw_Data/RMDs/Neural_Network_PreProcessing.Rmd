---
title: "Neural Network Pre-Processing"
author: Sierra Boyd
output:
  html_document:
    theme: cerulean
    toc: false
    code_folding: hide
editor_options: 
  chunk_output_type: console
---
#Load Packages
```{r}

library(tidyverse)
library(knitr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(ggpubr)
library(data.table)
library(conflicted)
library(readxl)
library(openxlsx)
library(patchwork)

conflicts_prefer(purrr::transpose())
conflicts_prefer(dplyr::filter())
conflicts_prefer(dplyr::lag())

```


```{r}
#Set wd to an an "export" folder
setwd("~")

```

# Import files and arrange data
```{r import data}
#Indicate input directory
project.input.dir <-"~"

#Make list of data files 
csv_files<- list.files(path=project.input.dir, pattern = "_burst_metrics\\.csv$", recursive = T, full.names = T) 

#Make vector for what the names of the basenames of the data files
data_frame_names<-gsub("_burst_metrics.csv","",basename(csv_files))

#Function to read in data files and make Group_IDs by separating assayTag
read_datafiles<-function(file){
  data<-read.csv(file)
  data<-data[-c(1),]
  data<-data[,-2]
  data$date<-gsub("-","",data$date)
  data$assayTag<-gsub(" ","_",data$assayTag)
  data<- data %>% separate(assayTag, c('DOP','Week','Type', 'PlateID'))
  data<-select(data,-c("DOP"))
  setnames(data,"div","DOP")
  data$Group_ID <- as.character(paste(data$"Group", data$"PlateID",data$"wellNo", sep = "_"))
  data<-as.data.table(data)
    }

#Use the read_datafiles function made above to read in data files
datalist<-lapply(csv_files,read_datafiles)

#Assign the names from the vector data_frame_names to the data frames just read in
for (i in seq_along(datalist)){
  assign(data_frame_names[i],datalist[[i]])
}

#Retrive the actual data frames
data_frames<-mget(data_frame_names)

#combine data frames into new df
fulldata<-rbindlist(data_frames,use.names=TRUE,fill=TRUE) 

#Make list of meta files
meta_file<-list.files(path=project.input.dir,pattern="eta\\.csv$", recursive = T, full.names = T)

read_meta<-function(file2){
  meta<-read.csv(file2)
  meta$wellNo<-as.character(meta$wellNo)
  meta$PlateID<-as.character(meta$PlateID)
  meta$Group_ID <- as.character(paste(meta$"Group", meta$"PlateID",meta$"wellNo", sep = "_"))
  meta<-select(meta,-c("PlateID","wellNo","Group"))
  assign("meta",meta,envir = .GlobalEnv)
  fulldata2 <- dplyr::full_join(meta,fulldata, by = "Group_ID")
  fulldata2<-subset(fulldata2 %>% filter(!grepl("Detached",Notes)))
  fulldata2[,8:15]<-lapply(fulldata2[,8:15],as.numeric)
  fulldata2$DOP_ID<-as.character(paste(fulldata2$"Group_ID", fulldata2$"DOP",sep = "_"))
  Doseorder<-c("Control",0.03,0.1,0.3,1,3,10,30,100)
  fulldata2$Dosage<-factor(fulldata2$Dosage,levels=Doseorder)
  fulldata2 <- fulldata2 %>%filter(!is.na(Group))
  assign("fulldata2",fulldata2,envir = .GlobalEnv)
}

metalist<-as.data.frame(lapply(meta_file,read_meta))

```

#Function to manually derive network metrics
```{r}
NetworkMetrics<-function(df){
SPB_Mean<- dplyr::group_by(df,DOP_ID) %>% dplyr::summarize(SPB_Mean=mean(SPB))%>%ungroup()
BurstPeak_Mean<- dplyr::group_by(df,DOP_ID) %>% dplyr::summarize(BurstPeak_Mean=mean(burstPeak))%>%ungroup()
#assign("SPB_Mean",SPB_Mean,envir = .GlobalEnv)
#assign("BurstPeak_Mean",BurstPeak_Mean,envir = .GlobalEnv)

##Make Burst Frequency Metric
#hist(df$IBI, breaks="Freedman-Diaconis") #check distribution 
BurstFreq<-df%>%count(instance,DOP_ID)
colnames(BurstFreq)[3]<-"counts"
BurstFreq$Freq <-(BurstFreq$counts/15) #15min recording
BurstFreq_Mean<-BurstFreq[,c("DOP_ID", "Freq")]
colnames(BurstFreq_Mean)[2]<-"BurstFreq"
#assign("BurstFreq_Mean",BurstFreq_Mean,envir = .GlobalEnv)

##Define Clusters
df$Cluster<-print("k")
ClusterDefine<-df%>%mutate(Cluster=ifelse(lag(IBI)>7.5,"start",Cluster))
ClusterDefine<-ClusterDefine %>% mutate(Cluster=ifelse(lead(Cluster)=="start","end",Cluster))
ClusterDefine$Cluster<-gsub("k","",ClusterDefine$Cluster)
ClusterDefine<-ClusterDefine%>%mutate(Cluster=case_when(Cluster=="start"~"start",Cluster=="end"~"end", TRUE~"Cluster"))
ClusterDefine<-ClusterDefine%>%group_by(DOP_ID)%>% mutate(start_sequence=row_number()*(Cluster=="start"))%>%ungroup()
ClusterDefine<-ClusterDefine%>% group_by(grp=cumsum(Cluster=="start"))%>%mutate(start_sequence=ifelse(Cluster=="start", start_sequence, start_sequence[1]))%>%ungroup()
ClusterDefine$Burstlet_ID<- as.character(paste(ClusterDefine$"Cluster", ClusterDefine$"start_sequence", sep = "_"))
ClusterDefine$Burstlet_Timepoint_ID<- as.character(paste(ClusterDefine$"DOP_ID", ClusterDefine$"start_sequence", sep = "_"))
ClusterDefine$Start_Timepoint_ID<- as.character(paste(ClusterDefine$"DOP_ID", ClusterDefine$"Burstlet_ID", sep = "_"))
ClusterDefine<- ClusterDefine %>% separate(Burstlet_ID, c('Timing'))
ClusterDefine$burstTime<-as.numeric(ClusterDefine$burstTime)

#Isolate Burst Duration
BurstDur<-select(ClusterDefine,c("DOP_ID","burstDur"))
BurstDur_mean<- BurstDur %>% group_by(DOP_ID) %>% summarize(burstDur=mean(burstDur))%>%ungroup()

##Remove any data that does not have a complete burst or end followed by end value by making a binary column
ClusterDefine<-ClusterDefine%>%group_by(Burstlet_Timepoint_ID)%>%
  mutate(
    IncompleteCluster=ifelse(Timing=="end" & lag(Timing)=="end",1,0)) %>%
  ungroup()
##Remove any data that does not have a complete burst or only have either a start or end, but not both by making a binary column
ClusterDefine<-ClusterDefine%>%group_by(Burstlet_Timepoint_ID)%>%
  mutate(
    IncompleteCluster2=if_else(
      !("start" %in% Timing) | !("end" %in% Timing),
        1,0))%>%
        ungroup()
##Remove any data that does not have a complete burst or any clusters that have multiple end values 
ClusterDefine<-ClusterDefine%>%group_by(Burstlet_Timepoint_ID)%>%
  mutate(
    IncompleteCluster3=if_else(
   sum(Timing=="start")>1 | sum(Timing=="end")>1,
   1,0))%>% ungroup()
#Remove the incomplete clusters here
ClusterDefine <- ClusterDefine %>% filter(!(IncompleteCluster == 1 | IncompleteCluster2 == 1 | IncompleteCluster3 == 1))

##Calculate Cluster Duration
ClusterDefine2<-ClusterDefine%>%group_by(Burstlet_Timepoint_ID)%>% summarize(Duration=burstTime[Timing=="end"]-burstTime[Timing=="start"]) %>%ungroup()
ClusterDefine2<-ClusterDefine2%>%filter(Duration>=0)
ClusterDefine_meta<-ClusterDefine[,c("Group_ID","DOP","DOP_ID", "Burstlet_Timepoint_ID")]

#Need to rejoin to get back DOP_ID
ClusterDefine2 <- dplyr::full_join(ClusterDefine2,ClusterDefine_meta, by = "Burstlet_Timepoint_ID")
assign("ClusterDefine2",ClusterDefine2,envir = .GlobalEnv)
#assign("ClusterDefine_meta",ClusterDefine_meta,envir = .GlobalEnv)

ClusterDur_Mean<- dplyr::group_by(ClusterDefine2,DOP_ID) %>% dplyr::summarize(Duration=mean(Duration))
#assign("ClusterDur_Mean",ClusterDur_Mean,envir = .GlobalEnv)
  
##Calculate Cluster Frequency
ClusterFreq<-ClusterDefine%>% group_by(DOP_ID)%>%mutate(Counts=n_distinct(Burstlet_Timepoint_ID))%>%ungroup()
ClusterFreq<- dplyr::group_by(ClusterFreq,DOP_ID) %>% dplyr::summarize(Counts=mean(Counts))%>%ungroup()
ClusterFreq$Freq <-(ClusterFreq$Counts/15) #15 min recording
ClusterFreq_Mean<-ClusterFreq[,c("DOP_ID", "Freq")]
colnames(ClusterFreq_Mean)[2]<-"ClusterFreq"
#assign("ClusterFreq_Mean",ClusterFreq_Mean,envir = .GlobalEnv)

##Make metric called IBI by Removing end values of cluster and sum IBI per DOP_ID
IBI_Total<-subset(ClusterDefine %>% filter(!grepl("end",Timing)))
IBI_Total<-IBI_Total[complete.cases(IBI_Total$IBI),]
IBI_Mean<- dplyr::group_by(IBI_Total,DOP_ID) %>% dplyr::summarize(IBI=mean(IBI))%>%ungroup()
#assign("IBI_Mean",IBI_Mean,envir = .GlobalEnv)

#Calculate Inter-cluster-interval
ICI_total<-ClusterDefine%>%group_by(DOP_ID)%>%mutate(ICI_ID=ifelse(Timing=="start",lead(start_sequence),NA))%>%ungroup()
ICI_total<-ICI_total%>%mutate(ICI_ID=ifelse(lead(Timing)=="start", lead(ICI_ID),ICI_ID))
ICI_total <- ICI_total %>% filter(!(is.na(ICI_ID) ))
ICI_total$Timepoint_ICI_ID<- as.character(paste(ICI_total$"DOP_ID", ICI_total$"ICI_ID",sep = "_"))
ICI_total_subtract<-ICI_total%>%group_by(Timepoint_ICI_ID)%>% summarize(ICI=burstTime[Timing=="start"]-burstTime[Timing=="end"])%>%ungroup()
ICI_total_subtract <- ICI_total_subtract %>% filter(!(ICI <0))
ICI_total_subtract<- ICI_total_subtract %>% separate(Timepoint_ICI_ID, c('Group', 'PlateID','WellNo',"DOP","ICI_ID"))
ICI_total_subtract$DOP_ID<- as.character(paste(ICI_total_subtract$"Group", ICI_total_subtract$"PlateID", ICI_total_subtract$"WellNo", ICI_total_subtract$"DOP", sep = "_"))
ICI_Mean<- dplyr::group_by(ICI_total_subtract,DOP_ID) %>% dplyr::summarize(ICI=mean(ICI))%>%ungroup()
assign("ICI_Mean",ICI_Mean,envir = .GlobalEnv)%>%ungroup()

##Calculate Counts per Cluster
CountsperCluster<-ClusterDefine%>%count(start_sequence,Burstlet_Timepoint_ID)
colnames(CountsperCluster)[3]<-"counts"
CountsperCluster<- CountsperCluster %>% separate(Burstlet_Timepoint_ID, c('Group','PlateID','WellNo', "DOP","Burstlet"))
CountsperCluster$DOP_ID <- as.character(paste(CountsperCluster$"Group", CountsperCluster$"PlateID",CountsperCluster$"WellNo",CountsperCluster$"DOP",  sep = "_"))
CountsperCluster_mean<- dplyr::group_by(CountsperCluster,DOP_ID) %>% dplyr::summarize(CountsperCluster=mean(counts))
#assign("CountsperCluster_mean",CountsperCluster_mean,envir = .GlobalEnv)

#Merge and Reduce
dfs_toMerge<-c("SPB_Mean", "BurstPeak_Mean","BurstFreq_Mean","ClusterFreq_Mean","IBI_Mean","ICI_Mean","CountsperCluster_mean","ClusterDur_Mean","BurstDur_mean")
merge_by_dop<-function(SPB_Mean,BurstPeak_Mean){merge(SPB_Mean,BurstPeak_Mean,by="DOP_ID",all=TRUE)}
AllMetrics<-Reduce(merge_by_dop,mget(dfs_toMerge))
ClusterDefine_meta<-ClusterDefine[,c("DOP_ID","Group_ID","DOP")]
AllMetrics <- dplyr::full_join(AllMetrics,ClusterDefine_meta, by = "DOP_ID")
AllMetrics <- dplyr::full_join(AllMetrics,meta, by = "Group_ID")
AllMetrics <- AllMetrics %>%filter(!is.na(DOP_ID))#Clean
AllMetrics <- AllMetrics %>%filter(!is.na(DOP))#Clean
AllMetrics <- as.data.table(AllMetrics)
AllMetrics <- AllMetrics %>%
  filter(!duplicated(DOP_ID))
assign("AllMetrics",AllMetrics,envir = .GlobalEnv)
}

```

#Run Function
```{r}
NetworkMetrics(fulldata2)
```

#Merge data to meta files
```{r}
#Isolate only needed columns
date_meta<-fulldata2%>%select(c("date","DOP_ID"))

#full join meta back to data
AllMetrics<-full_join(date_meta,AllMetrics, by="DOP_ID")

```

#Melt df
```{r}
#Create long table format
AllMetrics_melt <- melt(AllMetrics, id.vars = c("DOP","Chemical","Dosage","Group_ID","date"),
                          measure.vars =c("SPB_Mean","BurstPeak_Mean","BurstFreq","ClusterFreq","IBI","ICI","CountsperCluster","Duration","burstDur"))
                          
#Rename melted variables
setnames(AllMetrics_melt,"variable","Endpoint")

#Remove duplicated rows here 
AllMetrics_melt<-AllMetrics_melt %>% distinct(DOP,Chemical,Dosage,Endpoint,value,date, .keep_all=TRUE)
```

#Plot for each plate type over time
```{r}
#Set plate types here. If the plate serial number starts in T it is a 24-well plate, M is for 6-well plate
AllMetrics_melt<-AllMetrics_melt%>%
  mutate(Plate_Type=ifelse(grepl("T",Group_ID),"Twenty Four","Six"))

#Isolate controls
AllMetrics_melt_Controls <-AllMetrics_melt%>%  filter((Dosage== "Control"))

#Check of NAs and remove
AllMetrics_melt_Controls<-subset(AllMetrics_melt_Controls,!is.na(value))

#Set variables as a factor
AllMetrics_melt_Controls$DOP<-as.factor(AllMetrics_melt_Controls$DOP)
AllMetrics_melt_Controls$value<-as.numeric(AllMetrics_melt_Controls$value)


#Check of duplicates and remove
AllMetrics_melt_Controls<-AllMetrics_melt_Controls%>%distinct(Group_ID,DOP,Chemical, Dosage, Plate_Type, value, Endpoint,.keep_all=TRUE)

#Edit Endpoint Names
AllMetrics_melt_Controls$Endpoint<-gsub("SPB_Mean","Number of Spikes per Burst",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("BurstPeak_Mean","Burst Peak (Hz)",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("BurstFreq","Burst Frequency (Counts/min)",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("ClusterFreq","Cluster Frequency (Counts/min)",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("IBI","Inter-Burst-Interval (ms)",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("ICI","Inter-Cluster-INterval (ms)",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("CountsperCluster","Number of Burst per Cluster",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("Duration","Cluster Duration (ms)",AllMetrics_melt_Controls$Endpoint)
AllMetrics_melt_Controls$Endpoint<-gsub("burstDur","Burst Duration (ms)",AllMetrics_melt_Controls$Endpoint)

#Set DOPs as a factor
order<-c(2,5,7,9,12,14,16,19,21,23,26,28)
AllMetrics_melt_Controls$DOP<-factor(AllMetrics_melt_Controls$DOP,levels=order)

#Graph controls for each plate type over time
NetworkScan_By_PlateType<-ggplot(AllMetrics_melt_Controls,aes(x=as.factor(DOP),y=value,fill=Plate_Type,color=Plate_Type,shape=Plate_Type))+
  geom_boxplot()+
  geom_point(position=position_dodge(width=0.75))+
  theme_minimal()+
  labs(
  y=paste(""),
  x="Days on Plate")+
  scale_fill_manual(values=c("grey90","grey20"))+
  scale_color_manual(values=c("grey40","grey10"))+
  scale_shape_manual(values=c(15,19))+
  facet_wrap(~Endpoint,scales="free",ncol=5)+
  theme(legend.position = "bottom")

NetworkScan_By_PlateType

ggsave("NetworkScan_By_PlateType.png",plot=NetworkScan_By_PlateType,bg="white",width=10.35,height=3)

```

#Save as csv file for AUC or tcplfit2
```{r}
write.csv(AllMetrics_melt,file = "~",row.names=F)
```

#Plot conrols over time
```{r}
#Set plate types here. If the plate serial number starts in T it is a 24-well plate, M is for 6-well plate
AllMetrics_melt<-AllMetrics_melt%>%
  mutate(Plate_Type=ifelse(grepl("T",Group_ID),"Twenty_four","Six"))

#Subset controls
AllMetrics_control <-AllMetrics_melt%>%  filter((Dosage== "Control"))

#Make DOPs factor with levels for graphing
order<-c(2,5,7,9,12,14,16,19,21,23,26,28)
AllMetrics_control$DOP<-factor(AllMetrics_control$DOP,levels=order)

#remove duplicate rows
AllMetrics_control<-AllMetrics_control%>%distinct(Group_ID,DOP,Endpoint,.keep_all=TRUE)

Controls_long<-AllMetrics_control

#Edit Endpoint Names
AllMetrics_control$Endpoint<-gsub("SPB_Mean","Number of Spikes per Burst",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("BurstPeak_Mean","Burst Peak (Hz)",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("BurstFreq","Burst Frequency (Counts/min)",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("ClusterFreq","Cluster Frequency (Counts/min)",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("IBI","Inter-Burst-Interval (ms)",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("ICI","Inter-Cluster-INterval (ms)",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("CountsperCluster","Number of Burst per Cluster",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("Duration","Cluster Duration (ms)",AllMetrics_control$Endpoint)
AllMetrics_control$Endpoint<-gsub("burstDur","Burst Duration (ms)",AllMetrics_control$Endpoint)


#Make vector of the unique endpoints in this df to call below
Endpoint<-unique(AllMetrics_control$Endpoint)

#Make empty list for plots to fill below
NetworkScan_Control_BoxPlots_plotlist<-list()

#For Loop to plot all Endpoints
for (k in Endpoint){
   df_subset<-AllMetrics_control[AllMetrics_control$Endpoint==k,]
  
  NetworkScan_Control_BoxPlots<-ggplot(df_subset,aes(x=factor(DOP),y=value,color=DOP))+
  theme_minimal()+
  labs(y=k,x="Days on Plate")+
  scale_color_manual(values=c("black","black","black","black","black","black","black","black","black","black","black","black"))+
  geom_boxplot(alpha=0.6,position = position_dodge(width=0.7))+
  geom_point(position = position_dodge(width=0.7))+
  theme(legend.position="none")

    
   print(NetworkScan_Control_BoxPlots)
  
   NetworkScan_Control_BoxPlots_plotlist[[k]]<-NetworkScan_Control_BoxPlots
   }

#Put all plots in one figure and save
NetworkScan_Control_BoxPlots<-ggarrange(plotlist=NetworkScan_Control_BoxPlots_plotlist)
NetworkScan_Control_BoxPlots<-annotate_figure(NetworkScan_Control_BoxPlots, top = text_grob("Network Scan Ontogeny for Controls",size=14))
NetworkScan_Control_BoxPlots

ggsave("NetworkScan_Control_BoxPlots.png",plot=NetworkScan_Control_BoxPlots,bg="white",width=14,height=8)

#CombineNumber of Spikes per Burst and Burst Peak plots for figure
Figure_plotlist<-c(NetworkScan_Control_BoxPlots_plotlist["Number of Spikes per Burst"],NetworkScan_Control_BoxPlots_plotlist["Burst Peak (Hz)"])

#Wrap plots for figure
Plots_for_Figure<-patchwork::wrap_plots(Figure_plotlist,ncol=2)+plot_annotation(title="Neural Network",theme = theme(plot.title = element_text(hjust = 0.5)))

Plots_for_Figure

ggsave("NetworkScan_Plots_forFig.png",plot=Plots_for_Figure,bg="white",width=6,height=2.57)

```

#Normalize data to control
```{r}
#Find mean of control data by DOP and Endpoint
Controls_long<-Controls_long%>% group_by(DOP,Endpoint,Plate_Type) %>% 
  summarize(control=mean(value))%>%
  ungroup()

#Merge back to df
fulldata <- full_join(AllMetrics_melt,Controls_long, by = c("DOP","Endpoint","Plate_Type"))

fulldata<-fulldata%>% group_by(DOP,Chemical,Dosage,Group_ID,Endpoint,Plate_Type) %>% 
  summarize(Norm=((value/control)*100))%>%
  ungroup()

#Remove duplicated rows
fulldata<-fulldata%>%distinct(Group_ID,DOP,Chemical,Endpoint,Plate_Type,.keep_all=TRUE)

```

#Calculate se
```{r}
#Make se function
se <- function(x) {
  sd(x) / sqrt(length(x))
}

#Calculate SE
se_results<-fulldata%>% dplyr::group_by(DOP,Endpoint,Dosage,Chemical) %>%
  summarise(se = se(Norm))%>%
  ungroup()

#Join back to original data set
fulldata<-full_join(fulldata,se_results, by=c("Chemical","DOP","Dosage","Endpoint"))

#Remove duplicated rows
fulldata<-fulldata%>%distinct(Group_ID,DOP,Chemical,Endpoint,Plate_Type,.keep_all=TRUE)

```

#Find mean of the Norm data
```{r}
#Calculate mean
fulldata<-fulldata%>% group_by(DOP,Endpoint,Dosage,Chemical,se) %>% 
  summarise(Mean = mean(Norm))%>%
  ungroup()
```

#Filter out pre-treatment days
```{r}
#Filter out DOP 2 which is a pre-treatment recording date
fulldata <- fulldata %>% filter(DOP != 2)

#Edit nomenclature
setnames(fulldata,"Chemical","trt")
setnames(fulldata,"Dosage","dose")
setnames(fulldata,"DOP","DIV")
```

```{r}
#Save df under a new name for later (this will be needed when plotting only one metric for figures later on)
Individual_plot_data<-fulldata

#Edit metric names
fulldata$Endpoint<-gsub("SPB_Mean","Number of Spikes per Burst",fulldata$Endpoint)
fulldata$Endpoint<-gsub("BurstPeak_Mean","Burst Peak (Hz)",fulldata$Endpoint)
fulldata$Endpoint<-gsub("BurstFreq","Burst Frequency (Counts/min)",fulldata$Endpoint)
fulldata$Endpoint<-gsub("ClusterFreq","Cluster Frequency (Counts/min)",fulldata$Endpoint)
fulldata$Endpoint<-gsub("IBI","Inter-Burst-Interval (ms)",fulldata$Endpoint)
fulldata$Endpoint<-gsub("ICI","Inter-Cluster-Interval (ms)",fulldata$Endpoint)
fulldata$Endpoint<-gsub("CountsperCluster","Number of Bursts per Cluster",fulldata$Endpoint)
fulldata$Endpoint<-gsub("Duration","Cluster Duration (ms)",fulldata$Endpoint)
fulldata$Endpoint<-gsub("burstDur","Burst Duration (ms)",fulldata$Endpoint)

#Check for any NAs in the data and rmove
fulldata <- fulldata[!is.na("DIV"),]
fulldata <- fulldata[!is.na("Mean"),]

```

#Plot Line graphs for every chemical and endpoint
```{r}
#Set dose and DIV as a factor
Doseorder<-c("Control",0.03,0.1,0.3,1,3,10,30,100)
fulldata$dose<-factor(fulldata$dose,levels=Doseorder)
order<-c(5,7,9,12,14,16,19,21,23,26,28)
fulldata$DIV<-factor(fulldata$DIV,levels=order)

#Set as dat table
fulldata<-as.data.table(fulldata)

#make endpoitn and chemical vectors to loop through below
Endpoint<-unique(fulldata$Endpoint)
Chemical<-unique(fulldata$trt)

#Make any lists to store graphs
plotlist<-list()
res1<-list()

#Loop through each chemical and endpoitn to graph
for (p in Chemical){
  df_chemical<-fulldata%>%filter(trt==p)
  
  for (o in Endpoint){
    df_endpoint<-df_chemical %>% filter(Endpoint==o)
    
    p_plot<-ggplot(df_endpoint,aes(x=factor(DIV),y=Mean,group=dose,color=factor(dose)))+
            geom_point(size=2.5,aes(shape=factor(dose),color=factor(dose)))+
                     geom_line(size=1.25,alpha=0.6,aes(color=factor(dose)))+
                    geom_errorbar(aes(ymin=Mean-se,ymax=Mean),width=0.3,alpha=0.8)+
                    scale_color_manual(values=c("gray20","darkgreen","springgreen3","springgreen2","turquoise3","dodgerblue3","dodgerblue4","navy","purple4","purple3"))+
                    scale_shape_manual(values=c(15,16,17,18,19,7,10))+ 
                    geom_hline(yintercept=100,linetype="dashed",color="black")+
                     labs(title=paste(p),
                          y=paste(o,'(% of Control)'),
                          x="Days on Plate",
                          color="Concentration (uM)",
                          shape="Concentration (uM)")+
                     theme_minimal()
                   
                   print(p_plot)
                  plotlist[[o]]<-p_plot
  }
  res1<-list(res1,plotlist)
}

Total_plots<-list(res1)
pdf("Network_LineGraphs.pdf",width=7,height=5)
for (plot in Total_plots){
  print(plot)
}

dev.off()

```
